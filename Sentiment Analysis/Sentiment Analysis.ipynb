{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pos = []\n",
    "labels_pos = []\n",
    "with open(\"./pos_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        text_pos.append(i) \n",
    "        labels_pos.append('pos')\n",
    "\n",
    "text_neg = []\n",
    "labels_neg = []\n",
    "with open(\"./neg_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        text_neg.append(i)\n",
    "        labels_neg.append('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text = text_pos[:int((.8)*len(text_pos))] + text_neg[:int((.8)*len(text_neg))]\n",
    "training_labels = labels_pos[:int((.8)*len(labels_pos))] + labels_neg[:int((.8)*len(labels_neg))]\n",
    "\n",
    "test_text = text_pos[int((.8)*len(text_pos)):] + text_neg[int((.8)*len(text_neg)):]\n",
    "test_labels = labels_pos[int((.8)*len(labels_pos)):] + labels_neg[int((.8)*len(labels_neg)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    lowercase = False,\n",
    "    max_features = 85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(\n",
    "    training_text + test_text)\n",
    "\n",
    "features_nd = features.toarray() # for easy use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd[0:len(training_text)], \n",
    "        training_labels,\n",
    "        train_size=0.80, \n",
    "        random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7601246105919003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf=RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7414330218068536\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.77      0.89      0.82       219\n",
      "        pos       0.64      0.43      0.51       102\n",
      "\n",
      "avg / total       0.73      0.74      0.73       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1281, 85)\n",
      "(321, 85)\n",
      "1281\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print len(y_train)\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Artificial Neural Networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(32,activation='relu',input_dim=85))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "#model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2752      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,929\n",
      "Trainable params: 4,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "lb = LabelEncoder()\n",
    "train_labels = lb.fit_transform(y_train)\n",
    "test_labels=lb.fit_transform(y_test)\n",
    "#train_labels = keras.utils.np_utils.to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1281 samples, validate on 321 samples\n",
      "Epoch 1/50\n",
      "1281/1281 [==============================] - 0s 218us/step - loss: 0.6356 - acc: 0.6792 - val_loss: 0.6085 - val_acc: 0.6822\n",
      "Epoch 2/50\n",
      "1281/1281 [==============================] - 0s 118us/step - loss: 0.5905 - acc: 0.6948 - val_loss: 0.5882 - val_acc: 0.6822\n",
      "Epoch 3/50\n",
      "1281/1281 [==============================] - 0s 117us/step - loss: 0.5612 - acc: 0.6995 - val_loss: 0.5616 - val_acc: 0.7009\n",
      "Epoch 4/50\n",
      "1281/1281 [==============================] - 0s 108us/step - loss: 0.5301 - acc: 0.7237 - val_loss: 0.5350 - val_acc: 0.7259\n",
      "Epoch 5/50\n",
      "1281/1281 [==============================] - 0s 129us/step - loss: 0.4989 - acc: 0.7533 - val_loss: 0.5123 - val_acc: 0.7508\n",
      "Epoch 6/50\n",
      "1281/1281 [==============================] - 0s 109us/step - loss: 0.4705 - acc: 0.7681 - val_loss: 0.4963 - val_acc: 0.7695\n",
      "Epoch 7/50\n",
      "1281/1281 [==============================] - 0s 104us/step - loss: 0.4476 - acc: 0.7806 - val_loss: 0.4864 - val_acc: 0.7788\n",
      "Epoch 8/50\n",
      "1281/1281 [==============================] - 0s 91us/step - loss: 0.4288 - acc: 0.7955 - val_loss: 0.4839 - val_acc: 0.7664\n",
      "Epoch 9/50\n",
      "1281/1281 [==============================] - 0s 97us/step - loss: 0.4118 - acc: 0.8017 - val_loss: 0.4826 - val_acc: 0.7757\n",
      "Epoch 10/50\n",
      "1281/1281 [==============================] - 0s 86us/step - loss: 0.3960 - acc: 0.8048 - val_loss: 0.4785 - val_acc: 0.7477\n",
      "Epoch 11/50\n",
      "1281/1281 [==============================] - 0s 93us/step - loss: 0.3817 - acc: 0.8244 - val_loss: 0.4829 - val_acc: 0.7601\n",
      "Epoch 12/50\n",
      "1281/1281 [==============================] - 0s 106us/step - loss: 0.3669 - acc: 0.8283 - val_loss: 0.4886 - val_acc: 0.7601\n",
      "Epoch 13/50\n",
      "1281/1281 [==============================] - 0s 118us/step - loss: 0.3536 - acc: 0.8407 - val_loss: 0.4876 - val_acc: 0.7695\n",
      "Epoch 14/50\n",
      "1281/1281 [==============================] - 0s 102us/step - loss: 0.3398 - acc: 0.8525 - val_loss: 0.4975 - val_acc: 0.7570\n",
      "Epoch 15/50\n",
      "1281/1281 [==============================] - 0s 90us/step - loss: 0.3287 - acc: 0.8525 - val_loss: 0.4996 - val_acc: 0.7539\n",
      "Epoch 16/50\n",
      "1281/1281 [==============================] - 0s 82us/step - loss: 0.3143 - acc: 0.8587 - val_loss: 0.5068 - val_acc: 0.7539\n",
      "Epoch 17/50\n",
      "1281/1281 [==============================] - 0s 80us/step - loss: 0.3012 - acc: 0.8689 - val_loss: 0.5101 - val_acc: 0.7570\n",
      "Epoch 18/50\n",
      "1281/1281 [==============================] - 0s 97us/step - loss: 0.2878 - acc: 0.8774 - val_loss: 0.5229 - val_acc: 0.7383\n",
      "Epoch 19/50\n",
      "1281/1281 [==============================] - 0s 83us/step - loss: 0.2726 - acc: 0.8868 - val_loss: 0.5351 - val_acc: 0.7570\n",
      "Epoch 20/50\n",
      "1281/1281 [==============================] - 0s 81us/step - loss: 0.2736 - acc: 0.8938 - val_loss: 0.5387 - val_acc: 0.7477\n",
      "Epoch 21/50\n",
      "1281/1281 [==============================] - 0s 81us/step - loss: 0.2518 - acc: 0.8962 - val_loss: 0.5459 - val_acc: 0.7414\n",
      "Epoch 22/50\n",
      "1281/1281 [==============================] - 0s 82us/step - loss: 0.2390 - acc: 0.9009 - val_loss: 0.5688 - val_acc: 0.7383\n",
      "Epoch 23/50\n",
      "1281/1281 [==============================] - 0s 87us/step - loss: 0.2273 - acc: 0.9102 - val_loss: 0.5837 - val_acc: 0.7352\n",
      "Epoch 24/50\n",
      "1281/1281 [==============================] - 0s 91us/step - loss: 0.2172 - acc: 0.9173 - val_loss: 0.5937 - val_acc: 0.7383\n",
      "Epoch 25/50\n",
      "1281/1281 [==============================] - 0s 87us/step - loss: 0.2064 - acc: 0.9188 - val_loss: 0.6107 - val_acc: 0.7414\n",
      "Epoch 26/50\n",
      "1281/1281 [==============================] - 0s 85us/step - loss: 0.1988 - acc: 0.9235 - val_loss: 0.6184 - val_acc: 0.7445\n",
      "Epoch 27/50\n",
      "1281/1281 [==============================] - 0s 87us/step - loss: 0.1918 - acc: 0.9321 - val_loss: 0.6368 - val_acc: 0.7352\n",
      "Epoch 28/50\n",
      "1281/1281 [==============================] - 0s 78us/step - loss: 0.1815 - acc: 0.9313 - val_loss: 0.6516 - val_acc: 0.7352\n",
      "Epoch 29/50\n",
      "1281/1281 [==============================] - 0s 98us/step - loss: 0.1733 - acc: 0.9391 - val_loss: 0.6894 - val_acc: 0.7352\n",
      "Epoch 30/50\n",
      "1281/1281 [==============================] - 0s 86us/step - loss: 0.1701 - acc: 0.9352 - val_loss: 0.7048 - val_acc: 0.7383\n",
      "Epoch 31/50\n",
      "1281/1281 [==============================] - 0s 87us/step - loss: 0.1629 - acc: 0.9422 - val_loss: 0.7163 - val_acc: 0.7321\n",
      "Epoch 32/50\n",
      "1281/1281 [==============================] - 0s 87us/step - loss: 0.1549 - acc: 0.9454 - val_loss: 0.7356 - val_acc: 0.7383\n",
      "Epoch 33/50\n",
      "1281/1281 [==============================] - 0s 82us/step - loss: 0.1485 - acc: 0.9430 - val_loss: 0.7635 - val_acc: 0.7321\n",
      "Epoch 34/50\n",
      "1281/1281 [==============================] - 0s 85us/step - loss: 0.1415 - acc: 0.9485 - val_loss: 0.7933 - val_acc: 0.7445\n",
      "Epoch 35/50\n",
      "1281/1281 [==============================] - 0s 86us/step - loss: 0.1350 - acc: 0.9516 - val_loss: 0.8023 - val_acc: 0.7196\n",
      "Epoch 36/50\n",
      "1281/1281 [==============================] - 0s 85us/step - loss: 0.1321 - acc: 0.9555 - val_loss: 0.8209 - val_acc: 0.7290\n",
      "Epoch 37/50\n",
      "1281/1281 [==============================] - 0s 90us/step - loss: 0.1256 - acc: 0.9571 - val_loss: 0.8338 - val_acc: 0.7259\n",
      "Epoch 38/50\n",
      "1281/1281 [==============================] - 0s 124us/step - loss: 0.1205 - acc: 0.9555 - val_loss: 0.8655 - val_acc: 0.7321\n",
      "Epoch 39/50\n",
      "1281/1281 [==============================] - 0s 111us/step - loss: 0.1169 - acc: 0.9602 - val_loss: 0.8955 - val_acc: 0.7352\n",
      "Epoch 40/50\n",
      "1281/1281 [==============================] - 0s 100us/step - loss: 0.1164 - acc: 0.9586 - val_loss: 0.9064 - val_acc: 0.7196\n",
      "Epoch 41/50\n",
      "1281/1281 [==============================] - 0s 89us/step - loss: 0.1085 - acc: 0.9617 - val_loss: 0.9188 - val_acc: 0.7290\n",
      "Epoch 42/50\n",
      "1281/1281 [==============================] - 0s 80us/step - loss: 0.1052 - acc: 0.9586 - val_loss: 0.9397 - val_acc: 0.7352\n",
      "Epoch 43/50\n",
      "1281/1281 [==============================] - 0s 95us/step - loss: 0.1047 - acc: 0.9610 - val_loss: 0.9699 - val_acc: 0.7259\n",
      "Epoch 44/50\n",
      "1281/1281 [==============================] - 0s 79us/step - loss: 0.1036 - acc: 0.9625 - val_loss: 0.9736 - val_acc: 0.7352\n",
      "Epoch 45/50\n",
      "1281/1281 [==============================] - 0s 92us/step - loss: 0.1019 - acc: 0.9571 - val_loss: 1.0017 - val_acc: 0.7259\n",
      "Epoch 46/50\n",
      "1281/1281 [==============================] - 0s 100us/step - loss: 0.0979 - acc: 0.9610 - val_loss: 1.0220 - val_acc: 0.7321\n",
      "Epoch 47/50\n",
      "1281/1281 [==============================] - 0s 102us/step - loss: 0.0950 - acc: 0.9649 - val_loss: 1.0441 - val_acc: 0.7321\n",
      "Epoch 48/50\n",
      "1281/1281 [==============================] - 0s 106us/step - loss: 0.0933 - acc: 0.9617 - val_loss: 1.0490 - val_acc: 0.7321\n",
      "Epoch 49/50\n",
      "1281/1281 [==============================] - 0s 98us/step - loss: 0.0913 - acc: 0.9617 - val_loss: 1.0691 - val_acc: 0.7321\n",
      "Epoch 50/50\n",
      "1281/1281 [==============================] - 0s 90us/step - loss: 0.0887 - acc: 0.9633 - val_loss: 1.0771 - val_acc: 0.7321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fddea00a390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,train_labels,batch_size=32,epochs=50,validation_data=(X_test,test_labels),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.79      0.81       227\n",
      "          1       0.54      0.59      0.56        94\n",
      "\n",
      "avg / total       0.74      0.73      0.74       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_pred, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
